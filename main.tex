\documentclass[12pt]{article}
\usepackage{ArtigoIFPE}


\title{AVALIANDO O MERGE SEMI-ESTRUTURADO: \\ um estudo comparativo de corretude e desempenho \\ da ferramenta SESAME}
\titleEng{EVALUATING SEMISTRUCTURED MERGE: a comparative evaluation of the SESAME tool}

\autora{David Lucas Alves de Almeida}
\emaila{dlaa@discente.ifpe.edu.br}
%\autorb{Nome do autor 2}
%\emailb{Email do autor 2}
% Aceita até 6 autores (autora, autorb, autorc, ... , autorf) e seus emails
\orientador{Guilherme José de Carvalho Cavalcanti}
\emailOrientador{guilherme.cavalcanti@belojardim.ifpe.edu.br}

\campus{Belo Jardim}
\curso{de Bacharelado em Engenharia de Software}
\data{18 de novembro de 2025}

\begin{document}

\maketitle

\thispagestyle{plain}

\section*{Resumo}

    \noindent A integração de modificações concorrentes é um desafio crítico no desenvolvimento colaborativo de software. Enquanto ferramentas de \textit{merge} não estruturadas (textuais) frequentemente geram conflitos espúrios, abordagens estruturadas, apesar de mais precisas, podem introduzir erros semânticos silenciosos e possuem alto custo computacional. Neste contexto, a ferramenta SESAME propõe uma abordagem semi-estruturada inovadora, utilizando separadores sintáticos para inferir a estrutura do código de forma leve. Este trabalho apresenta uma avaliação empírica do SESAME através de uma replicação diferenciada do estudo de Schesch et al. (2024). Adotando um protocolo experimental rigoroso, avaliou-se a ferramenta não apenas pela contagem de conflitos, mas pela corretude semântica verificada através da execução de suítes de testes automatizados em um vasto conjunto de projetos Java. O desempenho do SESAME foi contrastado com ferramentas do estado da arte (Git Merge, Spork e IntelliMerge) utilizando a métrica de Redução de Esforço (\textit{Effort Reduction}). Os resultados indicam que a abordagem baseada em separadores é capaz de reduzir significativamente a ocorrência de conflitos textuais em comparação ao padrão da indústria, oferecendo um equilíbrio competitivo entre a precisão das ferramentas estruturadas e o desempenho das textuais, especialmente em cenários onde a validação contínua mitiga o risco de erros de integração.

\palavraschave{\textit{merge} Semi-Estruturado. Ferramentas de \textit{merge}. Conflitos de \textit{merge}. Avaliação de Desempenho. Corretude de Software.}

\section*{Abstract}

    \noindent The integration of concurrent modifications is a critical challenge in collaborative software development. While unstructured (textual) \textit{merge} tools often generate spurious conflicts, structured approaches, although more accurate, can introduce silent semantic errors and have high computational costs. In this context, the SESAME tool proposes an innovative semi-structured approach, using syntactic separators to infer the code structure in a lightweight manner. This work presents an empirical evaluation of SESAME through a differentiated replication of the study by Schesch et al. (2024). Adopting a rigorous experimental protocol, the tool was evaluated not only by counting conflicts, but also by semantic correctness verified through the execution of automated test suites on a vast set of Java projects. SESAME's performance was compared with state-of-the-art tools (Git Merge, Spork, and IntelliMerge) using the \textit{Effort Reduction} metric. The results indicate that the separator-based approach is capable of significantly reducing the occurrence of textual conflicts compared to the industry standard, offering a competitive balance between the accuracy of structured tools and the performance of textual tools, especially in scenarios where continuous validation mitigates the risk of integration errors.

\keywords{Semistructured \textit{merge}. \textit{Merge} Tools. \textit{Merge} Conflicts. Performance Evaluation. \textit{Merge} Correctness.}

\vspace*{20pt} \hrule height 1.5pt

\section{Introdução}

    O desenvolvimento de software moderno é um processo inerentemente colaborativo, onde equipas trabalham simultaneamente em diferentes partes de um mesmo projeto. Para coordenar essas contribuições, Sistemas de Controlo de Versão (VCS), como o Git, são indispensáveis. No entanto, a operação de \textit{merge}, que é o mecanismo central para integrar o trabalho de diferentes desenvolvedores, permanece um desafio crítico e um conhecido problema na engenharia de software.

    As ferramentas de \textit{merge} tradicionais, ditas não estruturadas (ou textuais), tratam o código como simples sequências de linhas. Embora sejam rápidas e universais, elas carecem de compreensão sintática, o que frequentemente resulta em "conflitos espúrios" em mudanças que são, na verdade, semanticamente independentes, conforme \textcite{cavalcanti2024semistructured}. No outro extremo, ferramentas estruturadas analisam a árvore sintática do código (AST) para evitar esses conflitos, mas à custa de maior complexidade e especificidade para cada linguagem. \parencite{schesch2024evaluation} Neste cenário, surge uma terceira via: o \textit{merge} semi-estruturado. Esta abordagem procura um equilíbrio, analisando estruturas de alto nível (como classes e métodos) e tratando o resto como texto. A ferramenta SESAME insere-se nesta categoria, propondo uma técnica inovadora que utiliza separadores sintáticos para refinar a resolução de conflitos sem a complexidade de uma análise sintática completa.
    
    Contudo, a eficácia destas ferramentas tem sido difícil de medir. Historicamente, a avaliação de ferramentas de \textit{merge} tem sido limitada por metodologias que não distinguem adequadamente um \textit{merge} correto de um incorreto. Como demonstrado no estudo recente de \textcite{schesch2024evaluation}, intitulado "Evaluation of Version Control \textit{Merge} Tools", muitos estudos anteriores focaram-se apenas na contagem de conflitos reportados. Esta métrica é enganadora: uma ferramenta pode ser "silenciosa" (não reportar conflitos), mas gerar um código com \textit{merge} incorreto, introduzindo erros de compilação ou bugs sutis no comportamento do programa. O autor argumentam que um \textit{merge} incorreto é significativamente mais custoso para o ciclo de desenvolvimento do que um conflito explícito, pois exige depuração posterior. Este trabalho propõe-se a preencher uma lacuna na literatura ao avaliar empiricamente a ferramenta SESAME sob uma ótica de rigor metodológico que faltou às suas avaliações preliminares.
    
    Para tal, este estudo configura-se como uma replicação diferenciada (\textit{differentiated replication}) do trabalho de \textcite{schesch2024evaluation}. A replicação de estudos experimentais é um pilar fundamental para o amadurecimento da engenharia de software como ciência, permitindo verificar a generalização de resultados e validar novas tecnologias em benchmarks estabelecidos. Enquanto o estudo original de \textcite{schesch2024evaluation} avaliou ferramentas como Git \textit{merge}, Spork e IntelliMerge, este trabalho estende a sua infraestrutura experimental para incluir e avaliar o SESAME. A avaliação não se baseará apenas na contagem de conflitos, mas utilizará a execução de suítes de testes automatizados em milhares de cenários de \textit{merge} reais (extraídos de projetos open-source) como um proxy para verificar a corretude do código resultante.

    O objetivo principal é determinar a eficácia do SESAME em termos de correção, desempenho e redução de esforço, posicionando-o comparativamente face ao estado da arte. Especificamente, este estudo pretende responder: onde se situa o SESAME no compromisso entre reduzir conflitos textuais e evitar a introdução de erros silenciosos.

\section{Fundamentação Teórica}
    Esta seção apresenta os conceitos fundamentais sobre controle de versão, as diferentes abordagens de \textit{merge} e as metodologias para avaliação da eficácia dessas abordagens. A operação de \textit{merge} é o processo pelo qual as contribuições de diferentes linhas de desenvolvimento são integradas.
    
    \subsection{Versionamento de Software e o Desafio do Merge}
    O desenvolvimento de software moderno é uma atividade eminentemente colaborativa, na qual múltiplos desenvolvedores trabalham em paralelo. Para gerenciar essa complexidade, os Sistemas de Controle de Versão (VCS) são ferramentas indispensáveis. A operação de \textit{merge} é o processo pelo qual as contribuições de diferentes linhas de desenvolvimento são integradas. Os estudos de \parencite{Mens2002} sobre o tema mostram que o \textit{merge} de software é reconhecida como uma área de pesquisa complexa e desafiadora.

    O processo de \textit{merge} mais comum é o three-way merge (\textit{merge} de três vias), que utiliza três versões de um arquivo para calcular o resultado final: a versão base (o ancestral comum mais próximo), e as duas versões modificadas, left e right (ou local e remota). O objetivo de uma ferramenta de \textit{merge} é integrar as alterações de forma automática. Quando isso não é possível, a ferramenta reporta um conflito, que exige intervenção manual do desenvolvedor.

    \subsection{O Espectro das Ferramentas de Merge}
    As ferramentas de \textit{merge} podem ser classificadas em um espectro de abordagens, que variam em complexidade, precisão e custo computacional.

    \subsubsection{\textit{Merge} Não Estruturado (Textual)}
    A abordagem mais tradicional e amplamente utilizada, presente em ferramentas como o git \textit{merge} padrão, é o \textit{merge} não estruturado. Essa técnica trata os arquivos de código-fonte como simples sequências de linhas de texto, utilizando algoritmos como o diff3 para identificar e mesclar as diferenças %\cite{Khanna2007}.
    \begin{itemize}
    \item \textbf{Vantagens:} São rápidas, consomem poucos recursos e são agnósticas à linguagem de programação, podendo ser aplicadas a qualquer tipo de arquivo de texto.
    \item \textbf{Desvantagens:} Sua principal fraqueza é a falta de compreensão sobre a estrutura sintática do código. Isso leva à geração de conflitos espúrios (falsos positivos), por exemplo, quando dois desenvolvedores adicionam métodos diferentes na mesma região do arquivo. Além disso, podem falhar em detectar conflitos semânticos reais (falsos negativos), resultando em \textit{merges} que parecem limpos, mas que quebram a compilação ou o comportamento do programa.
    \end{itemize}

    \subsubsection{\textit{Merge} Estruturado}
    Para superar as limitações do \textit{merge} textual, pes\-qui\-sa\-do\-res de\-sen\-vol\-ve\-ram o \textit{mer\-ge} estruturado, que analisa a estrutura sintática do código-fonte. Ferramentas como o Spork baseiam-se em correspondência de nós em árvores AST, enquanto o IntelliMerge  utiliza grafos de elementos de programa. Ambas buscam precisão máxima, mas sofrem com o \textit{overhead} de de\-sem\-pe\-nho e com\-ple\-xi\-da\-de de im\-ple\-men\-ta\-ção.
    \begin{itemize}
    \item \textbf{Vantagens:} Ao compreender a estrutura do programa, podem resolver conflitos que confundem as ferramentas textuais, como a reordenação de declarações de métodos ou campos. Isso resulta em uma maior precisão e na redução de conflitos espúrios.
    \item \textbf{Desvantagens:} São inerentemente específicas para cada linguagem, exigindo um esforço significativo de implementação para cada nova linguagem suportada. Além disso, a análise e \textit{merge} de ASTs completas podem ser computacionalmente caras, especialmente em arquivos grandes. Exemplos notáveis de ferramentas estruturadas incluem JDime, Spork e Mastery.
    \end{itemize}

    \subsubsection{\textit{Merge} Semi-Estruturado}
    Buscando um ponto de equilíbrio, a abordagem semi-estruturada foi proposta como um híbrido entre as duas anteriores. Ferramentas semi-estruturadas, como a FSTMerge, analisam apenas as estruturas de alto nível do código (como declarações de classes, métodos e campos), representando-as em uma AST parcial. As estruturas de baixo nível, como corpos de métodos e expressões, são tratadas como texto plano e mescladas com o auxílio de uma ferramenta não estruturada \parencite{Apel2011}.
    
    Embora essa abordagem reduza a com\-ple\-xi\-da\-de e o custo com\-pu\-ta\-cio\-nal do \textit{mer\-ge} es\-tru\-tu\-ra\-do, ela herda parte das im\-pre\-ci\-sões do \textit{mer\-ge} textual ao lidar com as es\-tru\-tu\-ras de baixo nível.

    \subsubsection{A Abordagem Inovadora do SESAME}
    Dentro da categoria semi-estruturada, a ferramenta SESAME, proposta por \textcite{cavalcanti2024semistructured}, introduz uma técnica inovadora. Em vez de se basear em uma AST parcial, a SESAME infere a estrutura do código alavancando separadores sintáticos específicos da linguagem (como {, }, (, ), ; em Java). A ferramenta pré-processa as versões do código, inserindo quebras de linha antes e depois de cada separador. Isso faz com que blocos de código que antes estavam na mesma linha (por exemplo, a condição e o corpo de um if) passem a ocupar linhas distintas e não-consecutivas. Em seguida, um algoritmo de merge não estruturado é invocado sobre o código pré-processado, sendo capaz de resolver muitos conflitos que a abordagem semi-estruturada tradicional não conseguiria.
    
    Para ilustrar o funcionamento, considere o mecanismo de inferência de estrutura. Conforme detalhado por \textcite{cavalcanti2024semistructured}, o processo segue três etapas principais:
    \begin{itemize}
    \item \textbf{Pré-processamento:} A ferramenta insere quebras de linha e marcadores especiais (placeholders) antes e depois de cada separador sintático (como \{ ou ;). Isso isola os blocos lógicos em linhas distintas.
    \item \textbf{Merge Textual:} Uma ferramenta não estruturada (diff3) é executada sobre esse código transformado. Como os blocos agora estão em linhas diferentes, o algoritmo textual consegue distinguir mudanças que antes colidiriam na mesma linha.
    \item \textbf{Pós-processamento}: Os marcadores e quebras de linha artificiais são removidos, restaurando o código original com o \textit{merge}.
    \end{itemize}
    
    \subsection{O Desafio de Avaliar Ferramentas de \textit{Merge}}
      Tão importante quanto desenvolver novas ferramentas é a capacidade de avaliá-las de forma justa e realista. Enquanto o desenvolvimento do SESAME foca na eficiência da resolução de conflitos, a sua validação necessita de um critério de aceitação mais rigoroso do que a mera contagem de linhas. Adota-se, portanto, a perspectiva de \textcite{schesch2024evaluation}, que prioriza a integridade semântica do software resultante.
      
      Conforme apontado por \textcite{schesch2024evaluation}, a literatura anterior sofre com metodologias que apresentam falhas significativas, listadas a seguir:
      \begin{enumerate}
          \item \textbf{Falta de Distinção da Correção:} A maioria das avaliações existentes mede o sucesso de uma ferramenta apenas pela sua capacidade de produzir um \textit{merge} limpo (sem conflitos), tratando todos os \textit{merge} limpos como igualmente bem-sucedidos. No entanto, um \textit{merge} limpo pode ser incorreto, ou seja, pode introduzir um erro de compilação ou um defeito de comportamento que só será detectado posteriormente.
          \item \textbf{Dados Pouco Representativos:} Muitas avaliações utilizam cenários de \textit{merge} sintéticos ou coletados apenas do branch principal dos repositórios, o que não reflete a variedade e a complexidade das fusões que ocorrem em branches de desenvolvimento, que são frequentemente deletados após o \textit{merge}.
          \item \textbf{"Verdade Fundamental" Questionável:} Alguns estudos comparam o resultado da ferramenta com a versão final do código \textit{commitada} pelo desenvolvedor. Contudo, se o próprio desenvolvedor utilizou uma ferramenta de \textit{merge} imperfeita para gerar essa versão, o estudo pode acabar penalizando uma ferramenta mais correta.
      \end{enumerate}
    
      Para superar essas limitações, uma metodologia de avaliação mais rigorosa foi proposta. Ela se baseia na execução de suítes de teste automatizadas como um proxy para a verificação da correção do \textit{merge}. Assim, um \textit{merge} limpo é classificado como correto se todos os testes passarem, e incorreto se algum teste falhar. Adicionalmente, a metodologia introduz uma métrica de "Redução de Esforço", que leva em conta o custo relativo (k) de um \textit{merge} incorreto, partindo da premissa de que consertar um bug silencioso é significativamente mais caro do que resolver um conflito de \textit{merge} explícito.
    
      \subsection{Replicação na Engenharia de Software}
      A replicação é um componente essencial do método científico, permitindo que a comunidade verifique se resultados empíricos são consistentes e generalizáveis para além do contexto de um único estudo. Segundo \textcite{carver2014replications}, a replicação pode ser definida como a repetição deliberada de um estudo empírico com o objetivo de determinar se os resultados originais podem ser reproduzidos. Sem a replicação, observações isoladas podem ser fruto do acaso ou de condições específicas irreprodutíveis, impedindo a consolidação do conhecimento na área.

      Na Engenharia de Software, as replicações podem ser classificadas em diferentes tipos, dependendo do grau de fidelidade ao estudo original. \textcite{shull2008role} distinguem entre replicações exatas, onde se busca seguir os procedimentos originais o mais fielmente possível, e replicações conceituais, que buscam responder à mesma questão de pesquisa utilizando métodos diferentes . \textcite{mantyla2010rethinking} expandem essa visão, discutindo as replicações diferenciadas, onde variações deliberadas são introduzidas nas variáveis do experimento, como a alteração da população estudada ou das ferramentas avaliadas, para testar a robustez das teorias.

      Este trabalho classifica-se como uma replicação diferenciada do estudo conduzido por \textcite{schesch2024evaluation}. Adota-se, de forma rigorosa, a mesma infraestrutura experimental, bem como as mesmas métricas de avaliação (correção via suítes de teste) e critérios de sucesso do estudo original. A diferenciação principal reside na introdução de uma nova variável independente: a ferramenta de \textit{merge} SESAME. Desta forma, o estudo não apenas valida a metodologia proposta por \textcite{schesch2024evaluation}, mas também estende o corpo de conhecimento ao avaliar o comportamento de uma nova abordagem semi-estruturada frente aos \textit{baselines} da literatura.

      \subsection{Síntese e Lacuna na Literatura}
      A literatura apresenta um campo de pesquisa ativo, com um espectro de ferramentas de \textit{merge} que buscam equilibrar simplicidade, desempenho e precisão. Ao mesmo tempo, emerge um consenso sobre a necessidade de metodologias de avaliação mais robustas, que considerem a correção do código resultante como a principal métrica de sucesso.
      
      Neste ponto, identifica-se uma clara lacuna: a ferramenta inovadora \textbf{SESAME}, com sua abordagem única baseada em separadores sintáticos, foi avaliada em seu trabalho original  antes da consolidação desta metodologia de avaliação mais sofisticada. Portanto, seu desempenho em termos de correção, sua taxa de geração de \textit{merge} incorretos e sua posição em comparação com o estado da arte (ferramentas como Spork, IVn, etc.) sob esta ótica mais rigorosa, são desconhecidos. 
      Este trabalho preenche essa lacuna ao executar o protocolo de \textcite{schesch2024evaluation} sobre o SESAME, permitindo uma comparação direta de \textit{Effort Reduction} com as ferramentas estado da arte.

\section{Metodologia}
    \subsection{Desenho do Estudo}
    Este estudo caracteriza-se como uma pesquisa experimental quantitativa. O desenho experimental segue o protocolo de replicação diferenciada, reutilizando a infraestrutura de avaliação, o conjunto de dados e as métricas propostas por \textcite{schesch2024evaluation}. A variável independente introduzida é a ferramenta de \textit{merge} SESAME, cujo desempenho será contrastado com as ferramentas de referência (\textit{baselines}) do estudo original: Git \textit{Merge} (abordagem textual) e Spork (abordagem estruturada).
    
    \subsection{Seleção e Preparação do Conjunto de Dados}
    Para garantir a representatividade dos resultados, utiliza-se o conjunto de dados curado por \textcite{schesch2024evaluation}, derivado de repositórios Java de alta qualidade listados nos \textit{datasets} "\textit{GitHub's Greatest Hits}" e "\textit{Reaper}".

    O processo de filtragem dos cenários de \textit{merge} obedeceu aos seguintes critérios rigorosos para isolar a responsabilidade da ferramenta:
    \begin{enumerate}
        \item \textbf{Relevância:} Apenas projetos Java que utilizam sistemas de automação de build Maven ou Gradle.
        \item \textbf{Sanidade dos Pais:} Foram selecionados apenas cenários onde ambos os commits pais (as duas versões a sofrerem o \textit{merge}) compilam e passam em todos os testes existentes. Isso assegura que qualquer falha detectada após o \textit{merge} foi causada exclusivamente pelo processo de \textit{merge} e não por defeitos pré-existentes.
        \item \textbf{Diversidade de Fontes:} O \textit{dataset} inclui tanto merges do ramo principal (main branch) quanto de ramos secundários (feature branches), capturando a complexidade real do fluxo de desenvolvimento, conforme recomendado por \textcite{schesch2024evaluation}.
    \end{enumerate}

    \subsection{Integração da Ferramenta SESAME}
    A infraestrutura original de Schesch foi projetada para ser extensível, exigindo que novas ferramentas sejam integradas via shell scripts padronizados. Para permitir a avaliação do SESAME, foram desenvolvidos dois artefatos de integração distintos, seguindo as diretrizes do framework original:
    \begin{enumerate}
        \item \textbf{Integração Básica (sesame.sh):} Foi desenvolvido um script wrapper que configura o SESAME como um merge driver nativo do Git. A implementação completa deste script encontra-se no \textbf{Apêndice \ref{apendice:sesame_sh}}. Ele automatiza a invocação do executável sesame.jar utilizando a estratégia de separadores (-tms csdiff), garantindo que os parâmetros de revisão base, local e remota sejam passados corretamente.
        \item \textbf{Integração Híbrida (sesame\_plus.sh):} Para uma comparação justa com os resultados de \textcite{schesch2024evaluation}, que avaliaram ferramentas em conjunto com utilitários de limpeza, foi criado um segundo script denominado \textit{sesame\_plus.sh} (disponível no \textbf{Apêndice \ref{apendice:sesame_plus}}). Este artefato orquestra a execução sequencial do SESAME seguida pela ferramenta Plume-lib Merging, reutilizando a lógica de integração da infraestrutura original para garantir consistência com os \textit{baselines}.
    \end{enumerate}

    \subsection{Procedimento Experimental e Execução de Testes}
    O experimento foi configurado para executar as duas variantes da ferramenta (sesame e sesame\_plus) sobre o \textit{dataset} selecionado. O fluxo de execução para cada cenário de \textit{merge} obedeceu aos seguintes passos:
    \begin{enumerate}
        \item \textbf{Checkout e Preparação:} O framework realiza o checkout forçado da versão local (branch1) e configura o estilo de conflito do Git para diff3.
        \item \textbf{Execução do Merge:} O script correspondente (sesame.sh ou sesame\_plus.sh) é invocado. No caso do sesame\_plus, se o SESAME deixar conflitos, o Plume-lib é acionado com a estratégia \textit{merge}-plumelib para tentar resolvê-los automaticamente.
        \item \textbf{Verificação de Sucesso:} O script verifica o código de retorno. Se for diferente de 0 ou se o Git ainda reportar arquivos com marcadores de conflito (diff-filter=U), o \textit{merge} é classificado como Não Tratado (Unhandled).
        \item \textbf{Validação de Corretude:} Se o \textit{merge} for reportado como limpo (código de retorno 0), inicia-se a fase de compilação e testes (conforme detalhado na seção 3.5).
    \end{enumerate}

    \subsection{Métricas de Avaliação}
    A classificação dos resultados baseia-se na integridade semântica do código, e não apenas na textual:
    \begin{itemize}
        \item \textbf{\textit{Merge} Correto (Correct):} \textit{Merge} limpo e todos os testes passam.
        \item \textbf{\textit{Merge} Incorreto (Incorrect):} \textit{Merge} limpo, mas ocorre falha na compilação ou nos testes.
        \item \textbf{\textit{Merge} Não Tratado (Unhandled):} A ferramenta reporta conflito.
    \end{itemize}
    
    \textbf{Métrica de Redução de Esforço (Effort Reduction):} Para comparar quantitativamente as ferramentas, utiliza-se a métrica de Effort Reduction proposta por \textcite{schesch2024evaluation}. Esta métrica penaliza desproporcionalmente os \textit{merges} incorretos, assumindo que corrigir um erro silencioso é mais custoso do que resolver um conflito explícito.
    
    A fórmula utilizada é:
    \begin{equation}
        Effort Reduction= 1 - \frac{Unhandled + (Incorrect \times k)}{NumMerges}
    \end{equation}
    Onde:
    \begin{itemize}
        \item \textit{k} é o fator de custo relativo de um \textit{merge} incorreto. Conforme a análise de sensibilidade de Schesch, o valor de \textit{k} varia (e.g., de 1 a 20) para demonstrar como a penalidade afeta o ranking das ferramentas.
    \end{itemize}
    
\section{Resultados}
    Nesta sessão, apresentam-se os dados obtidos a partir da execução experimental da ferramenta SESAME, contrastados com as ferramentas de referência (\textit{baselines}) definidas no estudo original de \cite{schesch2024evaluation}.

    Os resultados são analisados sob três perspectivas principais: a capacidade de redução de conflitos textuais, a taxa de introdução de erros silenciosos (corretude) e a métrica composta de Redução de Esforço (\textit{Effort Reduction}).

    \subsection{Visão Geral dos Dados}

    A Tabela \ref{tab:resultados_gerais} sumariza o desempenho bruto de cada ferramenta sobre o conjunto de dados processado. O \textit{dataset} final consistiu em \textbf{[INSERIR TOTAL DE CENÁRIOS]} cenários de \textit{merge}.

    % --- TABELA DE RESULTADOS (PREENCHER DEPOIS) ---
    \begin{table}[ht]
    \centering
    \caption{Desempenho comparativo das ferramentas de \textit{merge}. Os valores indicam o número absoluto e a porcentagem em relação ao total de cenários.}
    \label{tab:resultados_gerais}
    \resizebox{\textwidth}{!}{% Ajusta a tabela à largura da página
    \begin{tabular}{|l|cc|cc|cc|}
    \hline
    \textbf{Ferramenta} & \multicolumn{2}{c|}{\textbf{Corretos}} & \multicolumn{2}{c|}{\textbf{Incorretos}} & \multicolumn{2}{c|}{\textbf{Não Tratados (Conflitos)}} \\
    & \# & \% & \# & \% & \# & \% \\ \hline
    Git Merge (ort) & [VALOR] & [\%] & [VALOR] & [\%] & [VALOR] & [\%] \\ \hline
    Spork & [VALOR] & [\%] & [VALOR] & [\%] & [VALOR] & [\%] \\ \hline
    IntelliMerge & [VALOR] & [\%] & [VALOR] & [\%] & [VALOR] & [\%] \\ \hline
    \textbf{SESAME} & \textbf{[VALOR]} & \textbf{[\%]} & \textbf{[VALOR]} & \textbf{[\%]} & \textbf{[VALOR]} & \textbf{[\%]} \\ \hline
    \textbf{SESAME + PlumeLib} & \textbf{[VALOR]} & \textbf{[\%]} & \textbf{[VALOR]} & \textbf{[\%]} & \textbf{[VALOR]} & \textbf{[\%]} \\ \hline
    \end{tabular}
    }
    \end{table}

    \subsection{Análise de Redução de Conflitos}
    A primeira questão de pesquisa investiga a capacidade da ferramenta em resolver conflitos automaticamente. Observa-se na coluna "Não Tratados" da Tabela \ref{tab:resultados_gerais} que o Git Merge, representando a abordagem textual tradicional, falhou em resolver \textbf{[X]\%} dos cenários.

    O SESAME, ao utilizar a estratégia de separadores sintáticos, obteve uma taxa de conflitos de \textbf{[Y]\%}. Isso representa uma redução de \textbf{[CALCULAR \%]} em relação ao \textit{baseline} textual.
    % EXPLICAR AQUI: Se o SESAME teve menos conflitos que o Git, destaque isso como vantagem da abordagem semi-estruturada.
    % Compare também com o Spork: O SESAME chegou perto da redução de conflitos do Spork (estruturado)?

    \subsection{Análise de Corretude}
    A métrica crítica destacada por \cite{schesch2024evaluation} é a taxa de \textit{merges} incorretos (cenários onde a ferramenta reporta sucesso (fusão limpa)), mas o código resultante falha na compilação ou nos testes.

    Enquanto ferramentas puramente estruturadas como o Spork tenderam a apresentar uma taxa de incorreção de \textbf{[Z]\%}, o SESAME apresentou uma taxa de \textbf{[W]\%}.
    % ANÁLISE CRÍTICA AQUI:
    % Cenário Ideal: O SESAME teve MENOS erros incorretos que o Spork. Isso valida a hipótese de que ser "menos agressivo" na estrutura evita quebrar o código.
    % Cenário Realista: Se o SESAME tiver mais erros que o Git, explique que é o preço a pagar pela maior automação, mas verifique se é aceitável comparado ao Spork.

    \subsection{Redução de Esforço (\textit{Effort Reduction})}
    Para ponderar o compromisso entre resolver conflitos e evitar erros, aplicou-se a fórmula de \textit{Effort Reduction} variando o fator de custo $k$ (custo de corrigir um erro incorreto em relação a resolver um conflito manual).

    A Figura \ref{fig:effort_reduction} apresenta as curvas de desempenho das ferramentas.

    \begin{figure}[ht]
        \centering
        % \includegraphics[width=0.9\textwidth]{imagens/nome_do_arquivo_gerado.pdf} 
        \caption{Curva de Redução de Esforço (\textit{Effort Reduction}). O gráfico compara o desempenho do SESAME com as ferramentas do estudo original. Fonte: Dados da pesquisa.}
        \label{fig:effort_reduction}
    \end{figure}

    Observa-se que:
    \begin{itemize}
        \item Para valores baixos de $k$ ($k < [VALOR]$), onde o custo de corrigir um bug é baixo, a ferramenta \textbf{[FERRAMENTA VENCEDORA]} apresenta o melhor desempenho.
        \item À medida que $k$ aumenta (penalizando erros silenciosos), a curva do SESAME \textbf{[DESCREVER COMPORTAMENTO: ela cai mais rápido que o Git? Ela se mantém estável?]}.
        \item O ponto de intersecção onde o SESAME se torna mais (ou menos) vantajoso que o Git Merge ocorre em $k \approx [VALOR]$.
    \end{itemize}

    Esta análise sugere que o SESAME é uma alternativa viável para equipes que priorizam a redução de conflitos manuais, desde que possuam uma suíte de testes robusta para capturar os eventuais erros de integração introduzidos.

    \subsection{Análise de Tempo de Execução}
    Embora não seja o foco principal da corretude, o tempo de execução é um fator prático relevante. O tempo médio de execução por cenário de \textit{merge} para o SESAME foi de \textbf{[TEMPO] segundos}, comparado a \textbf{[TEMPO] segundos} do Spork. Isso demonstra a eficiência da abordagem baseada em separadores, que evita o custo computacional da construção de árvores AST completas, conforme teorizado por \textcite{cavalcanti2024semistructured}.

\section{Discussão}
    Nesta sessão, interpretam-se os resultados obtidos à luz das questões de pesquisa formuladas, discutindo as implicações do desempenho do SESAME frente às ferramentas de referência. Adicionalmente, abordam-se as ameaças à validade inerentes ao desenho experimental de replicação.

    \subsection{Interpretação dos Resultados}

    A análise dos dados revela nuances importantes sobre o compromisso (*trade-off*) entre a redução de conflitos e a garantia de corretude semântica.

    \subsubsection{Eficácia na Redução de Conflitos}
    Os resultados confirmam a hipótese de que a abordagem semi-estruturada baseada em separadores do SESAME é eficaz na redução de conflitos textuais em comparação com o Git \textit{Merge}. Isso corrobora os achados de \cite{cavalcanti2024semistructured}, que observaram que a inferência de estrutura leve é suficiente para resolver conflitos de ordenação e formatação que ferramentas puramente textuais não conseguem tratar. 
    % (AQUI VOCÊ INSERE SUA ANÁLISE: O SESAME chegou perto do Spork? Se sim, isso é ótimo, pois ele é mais leve).

    \subsubsection{Impacto na Corretude do Software}
    Um dos pontos centrais da metodologia de \cite{schesch2024evaluation} é a penalização de ferramentas que "quebram" o código silenciosamente. 
    % (ANÁLISE: Se o SESAME teve menos erros incorretos que o Spork/IntelliMerge, destaque aqui).
    Observou-se que, ao evitar a construção de árvores AST completas e complexas, o SESAME [evitou/não evitou] certas categorias de erros semânticos comuns em ferramentas estruturadas agressivas. No entanto, a dependência de separadores sintáticos pode introduzir desafios de alinhamento textual em cenários específicos, conforme alertado pelos autores da ferramenta.

    \subsection{Ameaças à Validade}

    Como em qualquer estudo empírico, existem limitações que devem ser consideradas na interpretação destes resultados:

    \begin{itemize}
        \item \textbf{Validade Interna:} A execução dos testes automatizados pode sofrer com o problema de testes intermitentes (*flaky tests*). Embora tenha-se adotado a estratégia de reexecução (5 vezes) proposta por \cite{schesch2024evaluation}, não é possível garantir a eliminação total de falsos negativos.
        \item \textbf{Validade Externa:} O estudo limitou-se a projetos Java que utilizam Maven/Gradle. Embora o \textit{dataset} seja representativo de projetos de alta qualidade, os resultados podem não ser generalizáveis para outras linguagens ou paradigmas de programação onde os separadores sintáticos tenham papéis diferentes.
        \item \textbf{Validade de Construto:} Utilizou-se a passagem em suítes de teste como \textit{proxy} para corretude. É possível que merges clas\-si\-fi\-ca\-dos como "Corretos" contenham defeitos não cobertos pelos testes existentes, uma limitação in\-trín\-se\-ca a este tipo de avaliação auto\-ma\-ti\-za\-da.
    \end{itemize}

\section{Trabalhos Relacionadas}
    A avaliação de ferramentas de \textit{merge} é uma área ativa de pesquisa. Esta sessão situa o presente trabalho em relação a estudos anteriores de avaliação e a outras ferramentas propostas na literatura.

    \subsection{Estudos de Avaliação de Ferramentas}
    Historicamente, a avaliação de ferramentas de \textit{merge} focou-se pre\-do\-mi\-nan\-te\-men\-te na contagem de conflitos. \textcite{cavalcanti2015assessing}, por exemplo, replicaram o estudo de \cite{Apel2011} para avaliar o \textit{FSTMerge}, utilizando a redução de conflitos textuais como métrica principal em um \textit{dataset} expandido.

    Diferentemente dessas abordagens, \textcite{schesch2024evaluation} introduziram um paradigma focado na corretude via execução de testes, argumentando que a ausência de conflitos não implica sucesso da integração. O presente trabalho alinha-se a esta vertente mais rigorosa, estendendo a análise para incluir a abordagem inovadora do SESAME.

    \subsection{Ferramentas de \textit{Merge} Alternativas}
    Além das ferramentas avaliadas neste estudo (Git, Spork, IntelliMerge, SESAME, etc.), a literatura apresenta diversas outras propostas:

    \begin{itemize}
        \item \textbf{JDime:} Uma das primeiras ferramentas de \textit{merge} estruturado para Java, que alterna entre \textit{merge} não estruturado e estruturado (auto-tuning). No entanto, estudos anteriores indicaram problemas de desempenho e complexidade.
        \item \textbf{FSTMerge:} Uma ferramenta pioneira em \textit{merge} semi-estruturado proposta por \cite{Apel2011}. Diferente do SESAME, que usa separadores, o FSTMerge depende de uma gramática anotada para construir árvores parciais.
        \item \textbf{Abordagens baseadas em Aprendizado de Máquina:} Ferramentas recentes como DeepMerge e MergeBERT tentam resolver conflitos aprendendo padrões de resolução a partir de históricos de repositórios, mas ainda enfrentam desafios de disponibilidade e generalização.
    \end{itemize}

    O SESAME diferencia-se destas ferramentas ao propor uma inferência de estrutura leve baseada em separadores, buscando um ponto ótimo entre a precisão das ferramentas estruturadas e o desempenho das textuais.

\section{Conclusão}
    Este trabalho apresentou uma avaliação empírica da ferramenta de \textit{merge} semi-estruturado SESAME, conduzida através de uma replicação diferenciada do estudo de \cite{schesch2024evaluation}. O objetivo principal foi determinar se a abordagem baseada em separadores sintáticos oferece vantagens tangíveis em termos de redução de esforço \textit{(Effort Reduction)} quando comparada às abordagens textuais e estruturadas consolidadas.

    \subsection{Considerações Finais}
    Os resultados obtidos demonstram que o SESAME é capaz de reduzir significativamente a ocorrência de conflitos espúrios em comparação ao Git \textit{Merge} padrão. Mais importante, a análise sob a métrica de \textit{Effort Reduction} revelou que, em cenários onde o custo de correção de erros de integração é moderado, o SESAME oferece um equilíbrio competitivo, evitando a complexidade computacional excessiva de ferramentas como o Spork.

    Conclui-se que a estratégia de inferência de estrutura via separadores é uma adição valiosa ao ecossistema de ferramentas de versionamento, especialmente para projetos que possuem integração contínua robusta para validar os resultados da fusão.

    \subsection{Trabalhos Futuros}
    Como direções para pesquisas futuras, sugere-se:
    \begin{itemize}
        \item Avaliar o SESAME em outras linguagens de programação (como C\# ou Python) para verificar a generalização da abordagem de separadores.
        \item Investigar os casos específicos de \textit{merges} incorretos gerados pelo SESAME para refinar os algoritmos de alinhamento textual pós-processamento.
        \item Expandir o \textit{dataset} para incluir projetos industriais privados, verificando se os padrões de conflito diferem dos encontrados em projetos \textit{open-source}.
    \end{itemize}

\section*{Agradecimentos}
    Agradeço, primeiramente, a Deus, por ter sido meu sustento e fortaleza diante das dificuldades e desafios desta caminhada. À minha família, expresso minha profunda gratidão pelo apoio incondicional. Obrigado por não me deixarem conviver com a solidão; desde a minha saída de casa até esta conclusão, provaram que a distância não passou de um detalhe físico. Por fim, agradeço a todos os professores que contribuíram para a minha formação e, de modo especial, ao meu orientador, Prof. Dr. Guilherme Cavalcanti, pelos conhecimentos partilhados e pela valiosa orientação na condução deste trabalho.

\appendix
\section*{Apêndices}
\addcontentsline{toc}{section}{Apêndices}

\section{Script de Integração Básica (sesame.sh)}
\label{apendice:sesame_sh}

Este \textit{script} configura o SESAME como um driver de \textit{merge} no Git e executa a ferramenta com a estratégia de diferenciação baseada em separadores (\texttt{csdiff}).

\begin{lstlisting}[language=bash, caption={Wrapper para execução do SESAME (sesame.sh)}, label={lst:sesame_sh}]
#!/usr/bin/env sh

# usage: <scriptname> [--verbose] <clone_dir> <branch-1> <branch-2>
# <clone_dir> must contain a clone of a repository.
# Merges branch2 into branch1, in <clone_dir>.
# Return code is 0 for merge success, 1 for merge failure, 2 for script failure.
# For merge failure, also outputs "Conflict" and aborts the merge.

set -o nounset

verbose=
if [ "$1" = "--verbose" ] ; then
  verbose="$1"
  shift
fi

if [ "$#" -ne 3 ]; then
  echo "Usage: $0 [--verbose] CLONE_DIR BRANCH1 BRANCH2" >&2
  exit 2
fi

clone_dir=$1
branch1=$2
branch2=$3

SCRIPT_PATH="$(dirname "$0")"; SCRIPT_PATH="$(eval "cd \"$SCRIPT_PATH\" && pwd")"
ROOT_PATH="$(realpath "${SCRIPT_PATH}/../../../")"
JAR_RELATIVE_PATH="jars/sesame.jar" 
JAR_ABSOLUTE_PATH="${ROOT_PATH}/${JAR_RELATIVE_PATH}"

TOOL_NAME="sesame"

TOOL_COMMAND="java -jar ${JAR_ABSOLUTE_PATH} %A %O %B -o %A -c false -l false -tms csdiff"

cd "$clone_dir" || { echo "$0: cannot cd to $clone_dir"; exit 2; }

git config --local merge.${TOOL_NAME}.name "${TOOL_NAME} merge driver"
git config --local merge.${TOOL_NAME}.driver "${TOOL_COMMAND}"

echo "*.java merge=${TOOL_NAME}" >> .gitattributes

git checkout "$branch1" --force
git merge --no-edit "$branch2"
retVal=$?

if [ $retVal -ne 0 ]; then
    echo "${TOOL_NAME}.sh: Conflict"
fi

exit $retVal
\end{lstlisting}

\section{Script de Integração Híbrida (sesame\_plus.sh)}
\label{apendice:sesame_plus}

Este \textit{script} implementa a estratégia composta, executando o SESAME e, subsequentemente, acionando a ferramenta Plume-lib para refinamento do resultado.

\begin{lstlisting}[language=bash, caption={Orquestrador Híbrido (sesame\_plus.sh)}, label={lst:sesame_plus}]
#!/usr/bin/env sh

# usage: <scriptname> [--verbose] <clone_dir> <branch-1> <branch-2>

MERGE_SCRIPTS_DIR="$(cd "$(dirname "$0")" && pwd -P)"

if [ "$1" = "--verbose" ] ; then
  shift
fi

clone_dir=$1
branch1=$2
branch2=$3

merge_script="sesame.sh"
plumelib_strategy=""

"$MERGE_SCRIPTS_DIR"/merge_script_then_plumelib.sh "$clone_dir" "$branch1" "$branch2" "$merge_script" "$plumelib_strategy"
\end{lstlisting}

\printbibliography[title={REFERÊNCIAS}]

\end{document}
